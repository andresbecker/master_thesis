{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "The objective of this notebook is train and evaluate a given model specified in the parameters file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Development and debugging:\n",
    "# Reload modul without restarting the kernel\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not touch the value of PARAMETERS_FILE!\n",
    "# When this notebook is executed with jupyter-nbconvert (from script), \n",
    "# it will be replaced outomatically\n",
    "PARAMETERS_FILE = 'dont_touch_me-input_parameters_file'\n",
    "if not os.path.exists(PARAMETERS_FILE):\n",
    "    raise Exception('Parameter file {} does not exist!'.format(PARAMETERS_FILE))\n",
    "    \n",
    "# Open parameters\n",
    "with open(PARAMETERS_FILE) as file:\n",
    "    p = json.load(file)\n",
    "p.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging configuration\n",
    "import logging\n",
    "log_file_path = p['log_file_name']\n",
    "logging.basicConfig(\n",
    "    filename=log_file_path,\n",
    "    filemode='w', \n",
    "    level=getattr(logging, p['log_level'])\n",
    ")\n",
    "logging.info('Parameters loaded from file:\\n{}'.format(PARAMETERS_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Dataset:\\n{}'.format(p['tf_ds_name'])\n",
    "msg += '\\nAugmentation:\\nRandom Flipping: {}\\nRandom 90deg Rotations: {}'.format(p['random_horizontal_flipping'],p['random_90deg_rotations'])\n",
    "msg += '\\nModel:\\nArchitecture: {}'.format(p['model_name'])\n",
    "msg += '\\nLoss function: {}'.format(p['loss'])\n",
    "msg += '\\nFirst trianing stage Epochs: {}'.format(p['first_trianing_stage_epochs'])\n",
    "msg += '\\nSecond trianing stage Epochs: {}'.format(p['second_trianing_stage_epochs'])\n",
    "msg += '\\nSecond trianing stage lr: {}\\n\\n'.format(p['second_trianing_stage_lr'])\n",
    "logging.info(msg)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load external libraries path\n",
    "EXTERNAL_LIBS_PATH = p['external_libs_path']\n",
    "if not os.path.exists(EXTERNAL_LIBS_PATH):\n",
    "    msg = 'External library path {} does not exist!'.format(EXTERNAL_LIBS_PATH)\n",
    "    logging.error(msg)\n",
    "    raise Exception(msg)\n",
    "else:\n",
    "    msg='EXTERNAL_LIBS_PATH: {}'.format(EXTERNAL_LIBS_PATH)\n",
    "    print(msg)\n",
    "    logging.info(msg)\n",
    "# Add EXTERNAL_LIBS_PATH to sys paths (for loading libraries)\n",
    "sys.path.insert(1, EXTERNAL_LIBS_PATH)\n",
    "# Load external libraries\n",
    "from Models import Predef_models as predef_models\n",
    "from Utils import Tee_Logger as Tee_Logger\n",
    "import Utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dirs where model output will be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to avoid cleaning (deleting) model dir, then uncomment the next line:\n",
    "#p['clean_model_dir'] = 0\n",
    "\n",
    "base_path, model_path, checkpoints_path = utils.create_model_dirs(parameters=p)\n",
    "\n",
    "msg = 'Base path:\\n{}'.format(base_path)\n",
    "msg += '\\nModel path:\\n{}'.format(model_path)\n",
    "msg += '\\nCheckpoints path:\\n{}'.format(checkpoints_path)\n",
    "logging.info(msg)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging configuration\n",
    "import logging\n",
    "log_file_path = os.path.join(base_path, p['log_file_name'])\n",
    "logging.basicConfig(\n",
    "    filename=log_file_path,\n",
    "    filemode='w', \n",
    "    level=getattr(logging, p['log_level'])\n",
    ")\n",
    "logging.info('Parameters loaded from file:\\n{}'.format(PARAMETERS_FILE))\n",
    "\n",
    "msg = 'Base path:\\n{}'.format(base_path)\n",
    "msg += '\\nModel path:\\n{}'.format(model_path)\n",
    "msg += '\\nCheckpoints path:\\n{}'.format(checkpoints_path)\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tf to ignore GPU\n",
    "if p['disable_gpu']:\n",
    "    msg = \"Cuda devices (GPUs) disabled\"\n",
    "    logging.info(msg)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "msg = 'Physical GPU devises:\\n{}'.format(physical_devices)\n",
    "logging.info(msg)\n",
    "print(msg)\n",
    "\n",
    "#restrict GPU mem\n",
    "if p['set_memory_growth']:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        msg = 'GPU Memory limited!'\n",
    "    except:\n",
    "        msg = 'It was not possible to limit GPU memory'\n",
    "        \n",
    "    logging.info(msg)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessing parameters and information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed data path\n",
    "pp_path = p['pp_path']\n",
    "\n",
    "with open(os.path.join(pp_path, 'params.json')) as file:\n",
    "    pp_params = json.load(file)\n",
    "msg = 'Loaded data preprocessing parameters from:\\n{}'.format(file)\n",
    "logging.info(msg)\n",
    "seed = pp_params['seed']\n",
    "\n",
    "# Load Channels file\n",
    "with open(os.path.join(pp_path, 'channels.csv')) as file:\n",
    "    channels = pd.read_csv(file)\n",
    "msg = 'Loaded channels file from:\\n{}'.format(file)\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify input channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = p['input_channels']\n",
    "msg = 'Selected input channels:\\n{}'.format(selected_channels)\n",
    "logging.info(msg)\n",
    "print(msg)\n",
    "# Get selected channel ids\n",
    "input_ids = np.array(channels.set_index(['name']).loc[selected_channels].channel_id.values)\n",
    "msg = 'Corresponding input channel ids:\\n{}'.format(input_ids)\n",
    "logging.info(msg)\n",
    "print(msg)\n",
    "print(input_ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Tensorflow dataset {} loaded from:\\n{}'.format(p['tf_ds_name'], p['local_tf_datasets'])\n",
    "logging.info(msg)\n",
    "\n",
    "# Path where tf datasets are\n",
    "dataset, metadata = tfds.load(\n",
    "    name=p['tf_ds_name'], \n",
    "    data_dir=p['local_tf_datasets'], \n",
    "    # If False, returns a dictionary with all the features\n",
    "    as_supervised=True, \n",
    "    shuffle_files=p['shuffle_files'],\n",
    "    with_info=True)\n",
    "\n",
    "# Load the splits\n",
    "train_data, val_data, test_data = dataset['train'], dataset['validation'], dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show information about the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data\n",
    "Before training the network, we discriminate some channels, apply some linear transformations (90deg rotations and horizontal flipping) to augment the **Training** dataset, create the batches and shuffle them. Also, we perform other operations to improve performance.\n",
    "\n",
    "**Tune performance**<br>\n",
    "tf.data.Dataset.prefetch overlaps data preprocessing and model execution while training.\n",
    "It can be used to decouple the time when data is produced from the time when data is consumed. In particular, the transformation uses a background thread and an internal buffer to prefetch elements from the input dataset ahead of the time they are requested. The number of elements to prefetch should be equal to (or possibly greater than) the number of batches consumed by a single training step. You could either manually tune this value, or set it to **tf.data.experimental.AUTOTUNE** which will prompt the tf.data runtime to tune the value dynamically at runtime.\n",
    "\n",
    "**Shuffling**<br>\n",
    "dataset.shuffle() Randomly shuffles the elements of this dataset.\n",
    "This dataset fills a buffer with `buffer_size` elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.\n",
    "\n",
    "For instance, if your dataset contains 10,000 elements but buffer_size is set to 1,000, then `shuffle` will initially select a random element from only the first 1,000 elements in the buffer. Once an element is selected, its space in the buffer is replaced by the next (i.e. 1,001-st) element, maintaining the 1,000 element buffer.\n",
    "\n",
    "**reshuffle_each_iteration** controls whether the shuffle order should be different for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source:\n",
    "# https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "\n",
    "def filter_channels(image, target):\n",
    "    \"\"\"Function to discriminated undecired channels\"\"\"\n",
    "    \n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    \n",
    "    n_channels = metadata.features['image'].shape[-1]\n",
    "    n_selected_channels = input_ids.shape[-1]\n",
    "    \n",
    "    # Create projection matrix base on selected channels\n",
    "    projection_tensor = np.zeros((n_channels, n_selected_channels))\n",
    "    for col, row in enumerate(input_ids):\n",
    "        projection_tensor[row,col] = 1\n",
    "    projection_tensor = tf.constant(projection_tensor, dtype=tf.float32)\n",
    "    \n",
    "    new_shape = image.shape[:-1]+(n_selected_channels,)\n",
    "    \n",
    "    return tf.reshape(tf.reshape(image, (-1,n_channels)) @ projection_tensor, (new_shape)), target\n",
    "\n",
    "def augment(image, target):\n",
    "    \"\"\"Function to augment dataset. After channel filtering, it flips (horizontally) and rotates (0, 90, 180, 270 degrees) randomly the images.\"\"\"\n",
    "    \n",
    "    image, target = filter_channels(image, target)\n",
    "    \n",
    "    # random Left and right flip\n",
    "    if p['random_horizontal_flipping']:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        \n",
    "    # random rotations\n",
    "    # Number of 90deg rotation\n",
    "    if p['random_90deg_rotations']:\n",
    "        k = np.random.randint(0,4)\n",
    "        image = tf.image.rot90(image, k=k)\n",
    "    \n",
    "    return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = ''\n",
    "if p['random_horizontal_flipping']:\n",
    "    msg = 'Random horizontal flipping for training set selected!'\n",
    "if p['random_90deg_rotations']:\n",
    "    msg = msg + '\\nRandom 90 degrees rotations (0, 90, 180 or 270 deg) for training set selected!'\n",
    "if msg == '':\n",
    "    msg = 'No data augmentation technique selected for trainingset!'\n",
    "logging.info(msg)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look into one image and a random transformation (random rotation+random horizontal flippig):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cell(image):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title('Original Cell')\n",
    "    plt.imshow(image.numpy()[:,:,10:13],\n",
    "               cmap=plt.cm.PiYG,\n",
    "               vmin=0, vmax=1)\n",
    "    \n",
    "    if p['random_horizontal_flipping'] | p['random_90deg_rotations']:\n",
    "        plt.figure(figsize=(15,4))\n",
    "        for i in range(4):\n",
    "            img, _ = augment(image, 0)\n",
    "            plt.subplot(1,4,i+1)\n",
    "            plt.title('Augmented Cell')\n",
    "            plt.imshow(img.numpy()[:,:,10:13],\n",
    "                       cmap=plt.cm.PiYG,\n",
    "                       vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one image from the training dataset\n",
    "image, _ = next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original vs. random flipping and rotations\n",
    "visualize_cell(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare datasets for training the CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = p['BATCH_SIZE']\n",
    "buffer_size = 512\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_data = (\n",
    "    train_data\n",
    "    .shuffle(buffer_size=buffer_size, reshuffle_each_iteration=True)\n",
    "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_data = (\n",
    "    val_data\n",
    "    .map(filter_channels, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_data = (\n",
    "    test_data\n",
    "    .map(filter_channels, num_parallel_calls=AUTOTUNE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "Models are selected from a group of predefined models in the class `Predef_models` (in `Models.py`). The name of the selected model is specified in the parameter `p['model_method']`.\n",
    "\n",
    "First we need to init the `Predef_models` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init models class\n",
    "models = predef_models()\n",
    "\n",
    "# Select model\n",
    "img_shape = metadata.features['image'].shape[:-1] + (input_ids.shape[0],)\n",
    "model = models.select_model(model_name=p['model_name'], input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the loss function and build the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the loss function\n",
    "if p['loss'] == 'mse':\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "elif p['loss'] == 'huber':\n",
    "    loss = tf.keras.losses.Huber(delta=1.0)\n",
    "msg = '{} loss function selected. Building the model...'.format(p['loss'])\n",
    "logging.info(msg)\n",
    "print(msg)\n",
    "\n",
    "metrics = ['mse', 'mean_absolute_error']\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss,\n",
    "              metrics=metrics\n",
    "             )\n",
    "msg = 'Model compiled!'\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look into the model architecture and number of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates sys.stdout to the log file\n",
    "TeeLog = Tee_Logger(log_file_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish stdout duplication\n",
    "TeeLog.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First stage of training\n",
    "\n",
    "First train only non-pretrained layers i.e. the last (dense) layers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set callback to save best weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoints_path+'/checkpoint_first_trianing_stage',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_freq='epoch',\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Starting first training stage...'\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates sys.stdout to the log file\n",
    "TeeLog = Tee_Logger(log_file_path)\n",
    "\n",
    "# Fit model\n",
    "n_train = metadata.splits['train'].num_examples\n",
    "first_trianing_stage_history = model.fit(train_data,\n",
    "                    validation_data=val_data,\n",
    "                    epochs=p['first_trianing_stage_epochs'],\n",
    "                    #epochs=2,\n",
    "                    callbacks=[model_checkpoint_callback],\n",
    "                    #verbose=1, #progress bar\n",
    "                    verbose=2, #one line per epoch\n",
    "                    #steps_per_epoch=math.ceil(n_train/BATCH_SIZE),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish stdout duplication\n",
    "TeeLog.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "with open(os.path.join(base_path, 'first_trianing_stage_history.json'), 'w') as file:\n",
    "    json.dump(first_trianing_stage_history.history, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'First training stage completed!\\n\\n\\n'\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Training Stage\n",
    "\n",
    "Now, train the whole architectur using a small learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all layers trainable\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile again the model using a smaller learning rate:\n",
    "model.compile(optimizer=Adam(learning_rate=p['second_trianing_stage_lr']),\n",
    "              loss=loss,\n",
    "              metrics=metrics\n",
    "             )\n",
    "msg = 'Model with all layers trainable compiled!'\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best weights from previous training\n",
    "model.load_weights(checkpoints_path+'/checkpoint_first_trianing_stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save te best model\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoints_path+'/best_model',\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_freq='epoch',\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all the layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Starting second training stage...'\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates sys.stdout to the log file\n",
    "TeeLog = Tee_Logger(log_file_path)\n",
    "\n",
    "second_trianing_stage_history = model.fit(train_data,\n",
    "                    validation_data=val_data,\n",
    "                    epochs=p['second_trianing_stage_epochs'],\n",
    "                    #epochs=2,\n",
    "                    callbacks=[model_checkpoint_callback],\n",
    "                    #verbose=1, #progress bar\n",
    "                    verbose=2, #one line per epoch\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish stdout duplication\n",
    "TeeLog.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "with open(os.path.join(base_path, 'second_trianing_stage_history.json'), 'w') as file:\n",
    "    json.dump(second_trianing_stage_history.history, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Second training stage completed!\\n\\n\\n'\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the last epoch model\n",
    "msg = 'Saiving trained model'\n",
    "logging.info(msg)\n",
    "\n",
    "# Save model\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the history of both models\n",
    "join_idx = np.argmin(first_trianing_stage_history.history['val_loss'])\n",
    "print('Best val_loss during first stage in epoch: {}'.format(join_idx))\n",
    "history = {}\n",
    "for k in first_trianing_stage_history.history.keys():\n",
    "    history[k] = first_trianing_stage_history.history[k][0:join_idx]+second_trianing_stage_history.history[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "with open(os.path.join(base_path, 'history.json'), 'w') as file:\n",
    "    json.dump(history, file, indent=4)\n",
    "    \n",
    "# Save parameters\n",
    "with open(os.path.join(base_path, 'parameters.json'), 'w') as file:\n",
    "    json.dump(p, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('base_path=\"{}\"\\n'.format(base_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load history\n",
    "#path = ''\n",
    "#with open(os.path.join(path, 'history.json'), 'r') as file:\n",
    "#    history = json.load(file)\n",
    "# Save parameters\n",
    "#with open(os.path.join(base_path, 'parameters.json'), 'r') as file:\n",
    "#    p = json.load(file)\n",
    "#metrics = ['mse', 'mean_absolute_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot History\n",
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(10,18))\n",
    "    keys = ['loss'] + metrics\n",
    "    for i, key in enumerate(keys,1):\n",
    "        warm_stage = int(join_idx + p['second_trianing_stage_epochs']*0.20)\n",
    "        min_val = np.asarray(history[key]+history['val_'+key]).min()\n",
    "        max_val = np.asarray(history[key][warm_stage:]+history['val_'+key][warm_stage:]).max()\n",
    "        \n",
    "        plt.subplot(3,1,i)\n",
    "        plt.plot(history[key], label=key)\n",
    "        plt.plot(history['val_'+key], label='val_'+key)\n",
    "        val_min = np.asarray(history['val_'+key]).min()\n",
    "        val_min_idx = np.argmin(history['val_'+key])\n",
    "        label='bets val value\\nEpoch={}\\n{}={}'.format(val_min_idx,key,round(val_min,2))\n",
    "        plt.scatter(x=val_min_idx, y=val_min, c='red', linewidths=4, label=label)\n",
    "        plt.grid(True)\n",
    "        plt.ylim([min_val, max_val])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(key)\n",
    "        plt.legend()\n",
    "        plt.title(key)\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Load the best weights into the model\n",
    "model.load_weights(os.path.join(checkpoints_path, 'best_model/variables/variables'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the dataset with flag `as_supervised=False` to load also the `mapobject_id_cell`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(train_data, val_data, test_data)\n",
    "del(dataset, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, metadata = tfds.load(\n",
    "    name=p['tf_ds_name'], \n",
    "    data_dir=p['local_tf_datasets'], \n",
    "    # If False, returns a dictionary with all the features\n",
    "    as_supervised=False, \n",
    "    shuffle_files=False,\n",
    "    with_info=True)\n",
    "\n",
    "train_data, val_data, test_data = dataset['train'], dataset['validation'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = p['BATCH_SIZE']\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_data = (\n",
    "    train_data\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_data = (\n",
    "    val_data\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_data = (\n",
    "    test_data\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['y', 'y_hat', 'mapobject_id_cell', 'set']\n",
    "targets_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "dss = [train_data, val_data, test_data]\n",
    "ds_names = ['train', 'val', 'test']\n",
    "for ds, dsn in zip(dss, ds_names):\n",
    "    for cells in ds:\n",
    "        cell_ids = [cell_id.decode() for cell_id in cells['mapobject_id_cell'].numpy()]\n",
    "        cell_ids = np.asarray(cell_ids).reshape(-1,1)\n",
    "        Y = cells['target'].numpy()\n",
    "        cell_imgs, _ = filter_channels(cells['image'], _)\n",
    "        Y_hat = model.predict(cell_imgs)\n",
    "        temp_df = pd.DataFrame(np.concatenate((Y, Y_hat), axis=1), columns=['y', 'y_hat'])\n",
    "        temp_df['mapobject_id_cell'] = cell_ids\n",
    "        temp_df['set'] = dsn\n",
    "        targets_df = pd.concat((targets_df, temp_df), axis=0, ignore_index=True)\n",
    "targets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sava targets info\n",
    "with open(os.path.join(base_path, 'targets.csv'), 'w') as file:\n",
    "    targets_df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Fited values\n",
    "Now lets see how our model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we plot the error distribution devided by set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = targets_df.copy()\n",
    "temp_df['diff'] = temp_df['y'] - temp_df['y_hat']\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "order = ['train', 'val', 'test']\n",
    "colors = ['orange', 'blue', 'green']\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.kdeplot(x='diff',\n",
    "            common_norm=True,\n",
    "            data=temp_df,\n",
    "            hue='set',\n",
    "            hue_order=order,\n",
    "            color=colors,\n",
    "            shade=True, \n",
    "            bw_method=0.2)\n",
    "plt.xlabel('y - y_hat')\n",
    "plt.title('Error KDE per set')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(y='diff',\n",
    "            x='set',\n",
    "            order=order,\n",
    "            data=temp_df)\n",
    "#sns.swarmplot(y='diff',\n",
    "#              x='set',\n",
    "#              dodge=True,\n",
    "#              order=order,\n",
    "#              color='red',\n",
    "#              size=3,\n",
    "#              data=temp_df)\n",
    "plt.ylabel('y - y_hat')\n",
    "plt.title('Error Distribution per set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare the distribution between *y* and *y_hat*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = targets_df.copy()\n",
    "temp_df = temp_df.set_index(['mapobject_id_cell', 'set']).stack().reset_index()\n",
    "temp_df.columns = ['mapobject_id_cell', 'set', 'var', 'value']\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.boxplot(y='value',\n",
    "            x='var',\n",
    "            hue='set',\n",
    "            hue_order=order,\n",
    "            data=temp_df)\n",
    "\n",
    "#sns.swarmplot(y='value',\n",
    "#              x='var',\n",
    "#              dodge=True,\n",
    "#              hue='set',\n",
    "#              hue_order=order,\n",
    "#              color='red',\n",
    "#              size=3,\n",
    "#              data=temp_df)\n",
    "plt.title('Transcription Rate (TR) values distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Notebook execution finished!'\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
