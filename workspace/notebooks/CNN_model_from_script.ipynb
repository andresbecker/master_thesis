{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "The objective of this notebook is train and evaluate a given model specified in the parameters file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not touch the value of PARAMETERS_FILE!\n",
    "# When this notebook is executed with jupyter-nbconvert (from script), \n",
    "# it will be replaced outomatically\n",
    "PARAMETERS_FILE = 'dont_touch_me-input_parameters_file'\n",
    "if not os.path.exists(PARAMETERS_FILE):\n",
    "    raise Exception('Parameter file {} does not exist!'.format(PARAMETERS_FILE))\n",
    "    \n",
    "# Open parameters\n",
    "with open(PARAMETERS_FILE) as params_file:\n",
    "    p = json.load(params_file)\n",
    "p.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dirs where model output will be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if path where model instances are saved exist\n",
    "try:\n",
    "    os.makedirs(p['model_path'], exist_ok=True)\n",
    "except OSError as e:\n",
    "    msg  = 'Dir {} could not be created!\\n\\nOSError: {}'.format(p['model_path'], e)\n",
    "    raise Exception(msg)\n",
    "    \n",
    "# Create directory where this execution will be saved (tagged with the date and time)\n",
    "time_tag = datetime.now().strftime(\"%d%m%y_%H%M\")\n",
    "base_path = os.path.join(p['model_path'], time_tag)\n",
    "if os.path.exists(base_path):\n",
    "    msg = 'Warning! Directory {} already exist! Deleting...\\n'.format(base_path)\n",
    "    print(msg)\n",
    "    try:\n",
    "        shutil.rmtree(base_path)\n",
    "    except OSError as e:\n",
    "        msg  = 'Dir {} could not be deleted!\\n\\nOSError: {}'.format(base_path, e)\n",
    "        raise Exception(msg)\n",
    "    msg = 'Creating dir: {}'.format(base_path)\n",
    "    print(msg)\n",
    "    os.makedirs(base_path, exist_ok=False)\n",
    "\n",
    "# Create dir for model and checkpoint saiving\n",
    "model_path = os.path.join(base_path, 'model')\n",
    "try:\n",
    "    os.makedirs(model_path, exist_ok=False)\n",
    "except:\n",
    "    msg  = 'Dir {} could not be created!'.format(model_path)\n",
    "    raise Exception(msg)\n",
    "    \n",
    "checkpoints_path = os.path.join(base_path, 'checkpoints')\n",
    "try:\n",
    "    os.makedirs(checkpoints_path, exist_ok=False)\n",
    "except:\n",
    "    msg  = 'Dir {} could not be created!'.format(checkpoints_path)\n",
    "    raise Exception(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging configuration\n",
    "import logging\n",
    "log_file_path = os.path.join(base_path, p['log_file_name'])\n",
    "logging.basicConfig(\n",
    "    filename=log_file_path,\n",
    "    filemode='w', \n",
    "    level=getattr(logging, p['log_level'])\n",
    ")\n",
    "logging.info('Parameters loaded from file:\\n{}'.format(PARAMETERS_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and set external libraries path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load external libraries path\n",
    "EXTERNAL_LIBS_PATH = p['external_libs_path']\n",
    "if not os.path.exists(EXTERNAL_LIBS_PATH):\n",
    "    msg = 'External library path {} does not exist!'.format(EXTERNAL_LIBS_PATH)\n",
    "    logging.error(msg)\n",
    "    raise Exception(msg)\n",
    "else:\n",
    "    msg='EXTERNAL_LIBS_PATH: {}'.format(EXTERNAL_LIBS_PATH)\n",
    "    logging.info(msg)\n",
    "    print(msg)\n",
    "# Add EXTERNAL_LIBS_PATH to sys paths (for loading libraries)\n",
    "sys.path.insert(1, EXTERNAL_LIBS_PATH)\n",
    "# Load external libraries\n",
    "from Models import Predef_models as predef_models\n",
    "from Utils import Tee_Logger as Tee_Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make tf to ignore GPU\n",
    "if p['disable_gpu']:\n",
    "    msg = \"Cuda devices (GPUs) disabled\"\n",
    "    logging.info(msg)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "msg = 'Physical GPU devises:\\n{}'.format(physical_devices)\n",
    "logging.info(msg)\n",
    "print(msg)\n",
    "\n",
    "#restrict GPU mem\n",
    "if p['set_memory_growth']:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        msg = 'GPU Memory limited!'\n",
    "    except:\n",
    "        msg = 'It was not possible to limit GPU memory'\n",
    "        \n",
    "    logging.info(msg)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessing parameters and information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed data path\n",
    "pp_path = p['pp_path']\n",
    "\n",
    "with open(os.path.join(pp_path, 'params.json')) as pp_file:\n",
    "    pp_params = json.load(pp_file)\n",
    "msg = 'Loaded data preprocessing parameters from:\\n{}'.format(pp_file)\n",
    "logging.info(msg)\n",
    "seed = pp_params['seed']\n",
    "\n",
    "# Load Channels file\n",
    "with open(os.path.join(pp_path, 'channels.csv')) as channel_file:\n",
    "    channels = pd.read_csv(channel_file)\n",
    "msg = 'Loaded channels file from:\\n{}'.format(channel_file)\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify input channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = p['input_channels']\n",
    "msg = 'Selected input channels:\\n{}'.format(selected_channels)\n",
    "logging.info(msg)\n",
    "print(msg)\n",
    "# Get selected channel ids\n",
    "input_ids = np.array(channels.set_index(['name']).loc[selected_channels].channel_id.values)\n",
    "msg = 'Corresponding input channel ids:\\n{}'.format(input_ids)\n",
    "logging.info(msg)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where tf datasets are\n",
    "dataset, metadata = tfds.load(\n",
    "    name=p['tf_ds_name'], \n",
    "    data_dir=p['local_tf_datasets'], \n",
    "    # If False, returns a dictionary with all the features\n",
    "    as_supervised=True, \n",
    "    shuffle_files=p['shuffle_files'],\n",
    "    with_info=True)\n",
    "msg = 'Tensorflow dataset {} loaded from:\\n{}'.format(p['tf_ds_name'], p['local_tf_datasets'])\n",
    "logging.info(msg)\n",
    "\n",
    "# Load the splits\n",
    "train_data, val_data, test_data = dataset['train'], dataset['validation'], dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show information about the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data\n",
    "Before training the network, we discriminate some channels, apply some linear transformations (90deg rotations and horizontal flipping) to augment the **Training** dataset, create the batches and shuffle them. Also, we perform other operations to improve performance.\n",
    "\n",
    "**Tune performance**<br>\n",
    "tf.data.Dataset.prefetch overlaps data preprocessing and model execution while training.\n",
    "It can be used to decouple the time when data is produced from the time when data is consumed. In particular, the transformation uses a background thread and an internal buffer to prefetch elements from the input dataset ahead of the time they are requested. The number of elements to prefetch should be equal to (or possibly greater than) the number of batches consumed by a single training step. You could either manually tune this value, or set it to **tf.data.experimental.AUTOTUNE** which will prompt the tf.data runtime to tune the value dynamically at runtime.\n",
    "\n",
    "**Shuffling**<br>\n",
    "dataset.shuffle() Randomly shuffles the elements of this dataset.\n",
    "This dataset fills a buffer with `buffer_size` elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required.\n",
    "\n",
    "For instance, if your dataset contains 10,000 elements but buffer_size is set to 1,000, then `shuffle` will initially select a random element from only the first 1,000 elements in the buffer. Once an element is selected, its space in the buffer is replaced by the next (i.e. 1,001-st) element, maintaining the 1,000 element buffer.\n",
    "\n",
    "**reshuffle_each_iteration** controls whether the shuffle order should be different for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source:\n",
    "# https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "\n",
    "def filter_channels(image, target):\n",
    "    \"\"\"Function to discriminated undecired channels\"\"\"\n",
    "    \n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    \n",
    "    n_channels = metadata.features['image'].shape[-1]\n",
    "    n_selected_channels = input_ids.shape[-1]\n",
    "    \n",
    "    # Create projection matrix base on selected channels\n",
    "    projection_tensor = np.zeros((n_channels, n_selected_channels))\n",
    "    for col, row in enumerate(input_ids):\n",
    "        projection_tensor[row,col] = 1\n",
    "    projection_tensor = tf.constant(projection_tensor, dtype=tf.float32)\n",
    "    \n",
    "    new_shape = image.shape[:-1]+(n_selected_channels,)\n",
    "    \n",
    "    return tf.reshape(tf.reshape(image, (-1,n_channels)) @ projection_tensor, (new_shape)), target\n",
    "\n",
    "def augment(image, target):\n",
    "    \"\"\"Function to augment dataset. After channel filtering, it flips (horizontally) and rotates (0, 90, 180, 270 degrees) randomly the images.\"\"\"\n",
    "    \n",
    "    image, target = filter_channels(image, target)\n",
    "    \n",
    "    # random Left and right flip\n",
    "    if p['random_horizontal_flipping']:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        \n",
    "    # random rotations\n",
    "    # Number of 90deg rotation\n",
    "    if p['random_90deg_rotations']:\n",
    "        k = np.random.randint(0,4)\n",
    "        image = tf.image.rot90(image, k=k)\n",
    "    \n",
    "    return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = ''\n",
    "if p['random_horizontal_flipping']:\n",
    "    msg = 'Random horizontal flipping for training set selected!'\n",
    "if p['random_90deg_rotations']:\n",
    "    msg = msg + '\\nRandom 90 degrees rotations (0, 90, 180 or 270 deg) for training set selected!'\n",
    "if msg == '':\n",
    "    msg = 'No data augmentation technique selected for trainingset!'\n",
    "logging.info(msg)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look into one image and a random transformation (random rotation+random horizontal flippig):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cell(image):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.title('Original Cell')\n",
    "    plt.imshow(image.numpy()[:,:,10:13],\n",
    "               cmap=plt.cm.PiYG,\n",
    "               vmin=0, vmax=1)\n",
    "    \n",
    "    if p['random_horizontal_flipping'] | p['random_90deg_rotations']:\n",
    "        plt.figure(figsize=(15,4))\n",
    "        for i in range(4):\n",
    "            img, _ = augment(image, 0)\n",
    "            plt.subplot(1,4,i+1)\n",
    "            plt.title('Augmented Cell')\n",
    "            plt.imshow(img.numpy()[:,:,10:13],\n",
    "                       cmap=plt.cm.PiYG,\n",
    "                       vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one image from the training dataset\n",
    "image, _ = next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original vs. random flipping and rotations\n",
    "visualize_cell(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare datasets for training the CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "buffer_size = 512\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_data = (\n",
    "    train_data\n",
    "    # since cache keeps images in memory, not shure if this will somehow avoid augmentation\n",
    "    #.cache()\n",
    "    .shuffle(buffer_size=buffer_size, reshuffle_each_iteration=True)\n",
    "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "val_data = (\n",
    "    val_data\n",
    "    #.cache()\n",
    "    .map(filter_channels, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_data = (\n",
    "    test_data\n",
    "    #.cache()\n",
    "    .map(filter_channels, num_parallel_calls=AUTOTUNE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "Models are selected from a group of predefined models in the class `Predef_models` (in `Models.py`). The name of the selected model is specified in the parameter `p['model_method']`.\n",
    "\n",
    "First we need to init the `Predef_models` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init models class\n",
    "models = predef_models()\n",
    "\n",
    "# Select model\n",
    "img_shape = metadata.features['image'].shape[:-1] + (input_ids.shape[0],)\n",
    "model = models.select_model(model_name=p['model_name'], input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.Huber(delta=1.0),\n",
    "              #loss=tf.keras.losses.MeanSquaredError(),\n",
    "              metrics=['mse', 'mean_absolute_error']\n",
    "              #metrics=['mse']\n",
    "             )\n",
    "msg = 'Model compiled'\n",
    "logging.info(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look into the model architecture and number of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates sys.stdout to the log file\n",
    "TeeLog = Tee_Logger(log_file_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish stdout duplication\n",
    "TeeLog.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redirect the systems standard output to the logfile, so we can see the training process in the server:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set callback to save best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoints_path+'/checkpoint',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_freq='epoch',\n",
    "    save_best_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Starting model training...'\n",
    "logging.info(msg)\n",
    "\n",
    "# Duplicates sys.stdout to the log file\n",
    "TeeLog = Tee_Logger(log_file_path)\n",
    "\n",
    "# Fit model\n",
    "n_train = metadata.splits['train'].num_examples\n",
    "history = model.fit(train_data,\n",
    "                    validation_data=val_data,\n",
    "                    epochs=p['number_of_epochs'],\n",
    "                    callbacks=[model_checkpoint_callback],\n",
    "                    #steps_per_epoch=math.ceil(n_train/BATCH_SIZE),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish stdout duplication\n",
    "TeeLog.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Saiving trained model'\n",
    "logging.info(msg)\n",
    "\n",
    "# Save model\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best weights\n",
    "model.load_weights(checkpoints_path+'/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "with open(os.path.join(base_path, 'history.json'), 'w') as histo_file:\n",
    "    json.dump(history.history, \n",
    "              histo_file, \n",
    "              indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot History\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.grid(True)\n",
    "    #plt.ylim([25,50])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "\n",
    "Now lets see how our model performs in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate test data\n",
    "batch_shape = (1,) + img_shape\n",
    "\n",
    "y_test = []\n",
    "y_test_hat = []\n",
    "for (cell_img, target) in test_data:\n",
    "    y_test.append(target.numpy()[0])\n",
    "    y_test_hat.append(model.predict(tf.reshape(cell_img, batch_shape))[0][0])\n",
    "y_test = np.asarray(y_test)\n",
    "y_test_hat = np.asarray(y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot distribution of errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = pd.DataFrame(y_test.reshape((-1,1)) - y_test_hat.reshape((-1,1)), columns=['diff'])\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.kdeplot(x='diff',\n",
    "            data=diff_df,\n",
    "            shade=True, \n",
    "            bw_method=0.2)\n",
    "plt.xlabel('y - y_hat')\n",
    "plt.title('Distribution of Errors')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(y='diff',\n",
    "            data=diff_df)\n",
    "sns.swarmplot(y='diff',\n",
    "              color='red',\n",
    "              data=diff_df)\n",
    "plt.ylabel('y - y_hat')\n",
    "plt.title('Errors BoxPlot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the distribution between *y* and *t_hat*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(y_test.reshape((-1,1)), columns=['values'])\n",
    "y_df['var'] = 'y'\n",
    "y_hat_df = pd.DataFrame(y_test_hat.reshape((-1,1)), columns=['values'])\n",
    "y_hat_df['var'] = 'y_hat'\n",
    "temp = pd.concat((y_df, y_hat_df), axis=0).reset_index()\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.boxplot(y='values',\n",
    "            x='var',\n",
    "            data=temp)\n",
    "sns.swarmplot(y='values',\n",
    "              x='var',\n",
    "              color='red',\n",
    "              data=temp)\n",
    "plt.title('Transcription Rate (TR) values distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = 'Notebook execution finished!'\n",
    "logging.info(msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
