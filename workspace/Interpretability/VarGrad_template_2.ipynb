{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Development and debugging:\n",
    "# Reload modul without restarting the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# Add EXTERNAL_LIBS_PATH to sys paths (for loading libraries)\n",
    "EXTERNAL_LIBS_PATH = '/home/hhughes/Documents/Master_Thesis/Project/workspace/libs'\n",
    "sys.path.insert(1, EXTERNAL_LIBS_PATH)\n",
    "\n",
    "# Load cortum libs\n",
    "import NN_interpretability as nn_inter\n",
    "import Data_augmentation as data_aug\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "params = {}\n",
    "\n",
    "params[\"input_data_dir\"] = \"/home/hhughes/Documents/Master_Thesis/Project/workspace/Interpretability/Cells\"\n",
    "params['base_path'] = '/home/hhughes/Documents/Master_Thesis/Project/workspace/Interpretability'\n",
    "params['model_dir'] = 'XC'\n",
    "params['CMA'] = 'CMA_0'\n",
    "params['cells'] = ['340547', '307720', '321021', '232615', '205760', '379184']\n",
    "\n",
    "score_maps_dir = os.path.join(params['base_path'], 'Score_maps', params['model_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.- Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.- Load general data (independent to the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "with open(os.path.join(params['base_path'], 'Metadata', 'filtered_metadata.csv'), 'r') as file:\n",
    "    metadata_df = pd.read_csv(file)\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "with open(os.path.join(params['base_path'], 'Metadata', 'parameters.json'), 'r') as file:\n",
    "    model_params = json.load(file)\n",
    "#model_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Channels\n",
    "with open(os.path.join(params['base_path'], 'Metadata', 'channels.csv'), 'r') as file:\n",
    "    channels_df = pd.read_csv(file)\n",
    "# Get input channel ids\n",
    "mask = channels_df.name.isin(model_params['input_channels'])\n",
    "input_ids = channels_df[mask].channel_id.values\n",
    "# Get output channel id\n",
    "mask = channels_df.name == '00_EU'\n",
    "output_id = channels_df[mask].channel_id.values[0]\n",
    "# Get normalization values\n",
    "norm_vals = channels_df.sort_values(by=['channel_id']).normalization_vals.values\n",
    "channels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.- Load Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "models = {}\n",
    "models_path = os.path.join(params['base_path'], 'Models', params['model_dir'])\n",
    "for model in os.listdir(models_path):\n",
    "    print('Loading model: ', model)\n",
    "    models[model] = tf.keras.models.load_model(os.path.join(models_path, model, params['CMA']))\n",
    "print('')\n",
    "models[model].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model_predictions\n",
    "models_path = os.path.join(params['base_path'], 'Models', params['model_dir'])\n",
    "targets_df = pd.DataFrame()\n",
    "for i, model in enumerate(os.listdir(models_path)):\n",
    "    print('Reading predicted values for model: ', model)\n",
    "    temp_path = os.path.join(models_path, model, 'targets_'+params['CMA']+'.csv')\n",
    "    with open(temp_path, 'r') as file:\n",
    "        temp_df = pd.read_csv(file)\n",
    "    temp_df = temp_df.drop(['y - y_hat'], axis=1)\n",
    "    prediction_name = 'y_hat'+'_'+model\n",
    "    temp_df[prediction_name] = temp_df.y_hat\n",
    "    temp_df = temp_df.drop(['y_hat'], axis=1)\n",
    "    if i == 0:\n",
    "        targets_df = temp_df.copy()\n",
    "    else:\n",
    "        temp_df = temp_df[['mapobject_id_cell', prediction_name]]\n",
    "        targets_df = targets_df.merge(temp_df, \n",
    "                                      left_on='mapobject_id_cell',\n",
    "                                      right_on='mapobject_id_cell',\n",
    "                                      how='left')\n",
    "targets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.- Load cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = targets_df.mapobject_id_cell.isin(np.array(params['cells'], dtype=np.int64))\n",
    "targets_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = {}\n",
    "n_cells = len(params['cells'])\n",
    "plt.figure(figsize=(n_cells*11,10))\n",
    "\n",
    "for i, cell in enumerate(params['cells'], 1):\n",
    "    temp_path = os.path.join(params['base_path'], 'Cells', cell+'.npz')\n",
    "    temp_cell = np.load(temp_path)\n",
    "    # Normalize cell\n",
    "    cells[cell+'_img'] = copy.deepcopy(temp_cell['img'] / norm_vals)\n",
    "    # filter accordingly to the input channels\n",
    "    cells[cell+'_img'] = cells[cell+'_img'][:,:,input_ids].astype(np.float32)\n",
    "    cells[cell+'_mask'] = copy.deepcopy(temp_cell['mask'])\n",
    "    \n",
    "    # Plot cells\n",
    "    temp_img = (cells[cell+'_img'] / np.max(cells[cell+'_img'], axis=(0,1)))[:,:,10:13]\n",
    "    plt.subplot(1, n_cells, i)\n",
    "    nn_inter.plot_cell(img=temp_img, title=cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: compute y_hat given the image and using loaded models\n",
    "for model in os.listdir(models_path):\n",
    "    print('Model: ', model)\n",
    "    for cell in params['cells']:\n",
    "        print('\\tmapobject_id_cell: '+cell)\n",
    "\n",
    "        train_tensor = tf.expand_dims(cells[cell+'_img'], axis=0)\n",
    "        y_true = round(targets_df.y[targets_df.mapobject_id_cell == int(cell)].values[0], 2)\n",
    "        y_hat = round(targets_df['y_hat_'+model][targets_df.mapobject_id_cell == int(cell)].values[0], 2)\n",
    "        y_hat_sanity = round(float(models[model].predict(train_tensor)[0][0]), 2)\n",
    "\n",
    "        print('\\t\\ty_true: {}, y_hat: {}, y_hat_sanity: {}'.format(y_true, y_hat, y_hat_sanity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.- Get Score Matrix for each cell (VarGrad IG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.- Load VarGrad IG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Score Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VarGrad_IG = {}\n",
    "for cell in os.listdir(score_maps_dir):\n",
    "    print('Loading Score map: '+cell)\n",
    "    \n",
    "    temp_path = os.path.join(score_maps_dir, cell)\n",
    "    if '.npy' in cell:\n",
    "        VarGrad_IG[cell[0:-4]] = np.load(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plote Score maps for both models and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = '379184'\n",
    "nn_inter.plot_VarGrad_IG_with_control(img=cells[cell+'_img'],\n",
    "                                      img_mask=cells[cell+'_mask'],\n",
    "                                      score_map_1=VarGrad_IG['Run_1_'+cell],\n",
    "                                      score_map_2=VarGrad_IG['Run_2_'+cell],\n",
    "                                      top_percent=0.4,\n",
    "                                      channels_df=channels_df,\n",
    "                                      img_size=(14,14),\n",
    "                                      score_map_same_sacale=False,\n",
    "                                      channels=[13, 23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot score maps for both models\n",
    "for cell in params['cells']:\n",
    "    print('Plotting cell: '+cell)\n",
    "    nn_inter.plot_VarGrad_IG_with_control(img=cells[cell+'_img'],\n",
    "                                          img_mask=cells[cell+'_mask'],\n",
    "                                          score_map_1=VarGrad_IG['Run_1_'+cell],\n",
    "                                          score_map_2=VarGrad_IG['Run_2_'+cell],\n",
    "                                          top_percent=1,\n",
    "                                          channels_df=channels_df,\n",
    "                                          img_size=(7,7),\n",
    "                                          score_map_same_sacale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in params['cells']:\n",
    "    print('Plotting cell: '+cell)\n",
    "    nn_inter.plot_VarGrad_IG_with_control(img=cells[cell+'_img'],\n",
    "                                          img_mask=cells[cell+'_mask'],\n",
    "                                          score_map_1=VarGrad_IG['Run_1_'+cell],\n",
    "                                          score_map_2=VarGrad_IG['Run_2_'+cell],\n",
    "                                          top_percent=0.5,\n",
    "                                          channels_df=channels_df,\n",
    "                                          img_size=(7,7),\n",
    "                                          score_map_same_sacale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in params['cells']:\n",
    "    print('Plotting cell: '+cell)\n",
    "    nn_inter.plot_VarGrad_IG_with_control(img=cells[cell+'_img'],\n",
    "                                          img_mask=cells[cell+'_mask'],\n",
    "                                          score_map_1=VarGrad_IG['Run_1_'+cell],\n",
    "                                          score_map_2=VarGrad_IG['Run_2_'+cell],\n",
    "                                          top_percent=0.2,\n",
    "                                          channels_df=channels_df,\n",
    "                                          img_size=(7,7),\n",
    "                                          score_map_same_sacale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in params['cells']:\n",
    "    print('Plotting cell: '+cell)\n",
    "    nn_inter.plot_VarGrad_IG_with_control(img=cells[cell+'_img'],\n",
    "                                          img_mask=cells[cell+'_mask'],\n",
    "                                          score_map_1=VarGrad_IG['Run_1_'+cell],\n",
    "                                          score_map_2=VarGrad_IG['Run_2_'+cell],\n",
    "                                          top_percent=0.1,\n",
    "                                          channels_df=channels_df,\n",
    "                                          img_size=(7,7),\n",
    "                                          score_map_same_sacale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in params['cells']:\n",
    "    print('Plotting cell: '+cell)\n",
    "    nn_inter.plot_VarGrad_IG_with_control(img=cells[cell+'_img'],\n",
    "                                          img_mask=cells[cell+'_mask'],\n",
    "                                          score_map_1=VarGrad_IG['Run_1_'+cell],\n",
    "                                          score_map_2=VarGrad_IG['Run_2_'+cell],\n",
    "                                          top_percent=0.05,\n",
    "                                          channels_df=channels_df,\n",
    "                                          img_size=(7,7),\n",
    "                                          score_map_same_sacale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
