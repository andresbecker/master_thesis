%% Magic command to compile root document
% !TEX root = ../../thesis.tex

%% Reset glossary to show long gls names
\glsresetall
\graphicspath{{./Sections/Results/Resources/}}

The models shown in this work were trained using the computing resources of the Institute of Computational Biology (ICB) of the Helmholtz Zentrum MÃ¼nchen (HMGU). Therefore, the training time of each model depends on the concurrency of the cluster and the node assigned by the job scheduling system (SLURM). For this reason, it is not possible to provide a fair comparison of the training time between models.

Since we are dealing with multichannel images, we may have highly correlated features in the data. For this reason, the model could focus on one or other features during training. For this reason, as a future work it would be interesting to train the models with different initializations, and validate that the score maps obtained are consistent. Another option could be to train the models aggregating correlated channels, based on the information obtained in the interpretability analysis.

Another validation method that was contemplated in this work, but that was not possible to complete, is the \gls{roar} \cite{hooker2018benchmark}. This method would have allowed us to observe to what extent the performance of the model would be degraded, by replacing the pixels marked as important by the interpretability methods by uninformative pixels. When comparing the increase in error against a random selection of pixels, this would show if the pixels selected as important were really better than just a random guessing. This could also help us to detect highly correlated features in the data.
