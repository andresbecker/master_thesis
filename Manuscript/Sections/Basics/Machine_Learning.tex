%% Magic command to compile root document
% !TEX root = ../../thesis.tex

%% Reset glossary to show long gls names
\glsresetall

%% Set path to look for the images
\graphicspath{{./Sections/Basics/Resources/}}

\glspl{ann} are universal approximators widely used in the field of \gls{ml} and an important part of this work. This is a very broad subject and there are entire books that cover this in detail, like  \cite{Goodfellow-et-al-2016} or \cite{bishop2006pattern}. However, in this section we will give a small introduction to \glspl{ann} and \glspl{cnn}, which are a type of \gls{ann} that were specifically designed to deal with data in the form of images.

Before defining what exactly is a \gls{ann}, lest first recall the definition of machine learning. We refer as \gls{ml} to the group of algorithms that automatically improve (learn) through experience. Among this algorithms, we could say that there are three main classes (which depend on the kind of experience we provide):

\begin{itemize}
  \item \textbf{Supervised Learning}: The experience is given in the form of input and output examples, and the goal is to learn a general rule that maps inputs to outputs.
  \item \textbf{Unsupervised Learning}: The experience is given in the form of data (no outputs provided) and the goal is to discover hidden patterns in data.
  \item \textbf{Reinforcement Learning}: No experience (data) is given, instead a dynamic \hl{environment} is provided and an \hl{agent} must learn how to interact with it in order to achieve a goal.
\end{itemize}

An \gls{ann} can be used in any of the 3 kinds of learning algorithms listed above.

However, recall that the objective of this work is to approximate a function (in this case a \gls{cnn}), such that when it is fed with images of a cell nucleus (input data), it predicts the corresponding \gls{tr} (output data) Therefore, we are dealing with a \hl{supervised learning} task.

Before explaining what a \gls{cnn} is, let us first introduce and explain \gls{ann} in general.
